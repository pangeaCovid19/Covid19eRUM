---
title: "La diffusione del Coronavirus tra previsioni e dati reali. Siamo giunti al picco?"
author: <span class="titolo2">Nicola Farina</span>
output: 
   html_document:
      css: style.css
---
Probabilmente no.

```{r ,results='hide', echo=FALSE}
source("scriptMD.R")
```


In data 18 Marzo, abbiamo lanciato la nostra applicazione che permette di monitorare la diffusione del Coronavirus in Italia tramite rappresentazioni geografiche, andamenti temporali e occupazione di posti in terapia intensiva. Oltre tutto questo, ci sono anche *previsioni* (il corsivo è d'obbligo, approfondiremo quanto punto più avanti) sul totale dei casi, i deceduti e le altre quantità monitorate dalla [Protezione Civile](https://github.com/pcm-dpc/COVID-19).

Come sono andate le nostre *previsioni* in questi primi giorni? Quanto buone *sarebbero* dovute essere? La risposta breve è: meglio di quanto sarebbe stato lecito attendersi (e meglio di quanto sia facile spiegare).

Prima di esaminare i risultati dal punto di vista tecnico, occorre fare un paio di premesse. Quando, di qui in poi, parleremo di  previsioni *buone* o *cattive*, intenderemo esclusivamente del loro valore in relazione al dato reale. In nessun altro contesto infatti si potrebbe definire buona una previsione che contempla la morte di centinaia di persone (come del resto fa il nostro modello e continuerà a fare per giorni). Ma al modello matematico che giace al di sotto della realtà e la astrae non interessa affatto di *cosa* si stia parlando.

La seconda premessa è più sottile, forse filosofica, e riguarda proprio il significato di previsione (ed è anche il motivo per cui abbiamo usato il corsivo fin dall'inizio). Una previsione scientifica si deve basare su un modello *robusto*, con solide basi logiche e capace di spiegare il meccanismo che c'è sotto al fenomeno e anticiparlo. Quanto c'è di questo nel *nostro* modello? Francamente poco. Abbiamo semplicemente verificato che l'andamento dei dati potesse essere di una qualche forma funzionale, che prende spunto da letteratura di fenomeni simili, ma di per sé non è totalmente giustificata. In più, ha evidenti problemi di corenza logica che il lettore più matematicamente smaliziato può individuare facilmente alla prima occhiata (come ad esempio l'andamento asintotico). Ecco perché al termine *previsione* preferiamo quello di [estrapolazione](https://it.wikipedia.org/wiki/Estrapolazione), che è poco più di un *continuare a tracciare un andamento* anche al di là di dove sia corretto che esso funzioni, senza porsi grossi problemi. Cionostante, tali *previsioni* hanno assolutamente diritto di esistere e una propria (e in questo caso oserei dire grossa) **utilità**. 

In casi come questi, occorre avere idea di quello che sta succedendo per poter interpretare la realtà e, conseguentemente, prendere **decisioni logiche e razionali**. Occorre, decisamente, saper *leggere* il dato. Le domande principali di fronte al fenomeno che stiamo vivendo sono infatti legate alla *velocità* con la quale il Coronavirus si sta diffondendo e l'*efficacia* delle misure restrittive. Un numero di contagi giornaliero, se  non accompagnato da un benchmark che abbia un qualche tipo di senso, non può essere interpretato per rispondere alle domande più cruciali. Proprio in ottica di fornire un benchmark sensato che abbiamo scelto il nostro modello.

Come spiegato nella sezione della descrizione dei modelli, la diffusione incontrollata di un virus ha un primo andamento di tipo *esponenziale*. Ed infatti, come verificheremo anche tra poco, le grandezze principali monitorate (decessi e casi totali) nei primi giorni della diffusione erano ben descritte da un andamento di quel tipo. Ci sono motivi solidi e scientifici per poter affermare che una diffusione non può essere più veloce che esponenziale, con un esponente lineare con il tempo (che di per sé è già un ritmo maledettamente veloce); di conseguenza il *benchmark* esponenziale rappresenta il **peggiore dei casi possibili**. Se infatti la diffusione procede a quel ritmo, vuol dire che le cose **non potrebbero andare peggio**.

Fortunatamente, la diffusione ad oggi ha rallentato un po' da quel ritmo infernale. Ma questo di per se vuol dire poco. Immaginate di essere in auto. Un ritmo esponenziale sarebbe come se voi raddoppiaste la velocità ogni secondo. Siete a 100km all'ora. Dopo un secondo a 200, poi a 400. Rallentare questo ritmo vuol dire, ad esempio, che il secondo successivo non arrivate a 800, ma magari a 700 all'ora. La vostra accelerazione rimane però elevatissima. 

Il rallentamento dal benchmark esponenziale può essere dovuto a vari fattori. Quello più sperabile, chiaramente, è che sia l'effetto delle misure contenitive. Non dobbiamo però sottovalutare altre cause. Anche in una situazione incontrollata, la diffusione ad un certo punto rallenta perché il virus trova meno persone da contagiare e perché la popolazione *potrebbe* immunizzarsi. C'è poi tutto il capitolo dell' *affidabilità* del dato. Ricordiamoci che questo non è un esperimento e il dato è molto spesso non pulito e dipendente anche da scelte dovute a contingenze, come ad esempio la scarsità di tamponi che impedisce di individuare con certezza tutti gli infetti.

Sia come sia, abbiamo modellizzato questo rallentamento con un termine *quadratico* al modello esponenziale. Tale modello ipotizza un andamento della diffusione che parte come esponenziale, ma con un ritmo che rallenta linearmente nel tempo. Come si può vedere nel [diario](./www/tabReport.html) che pubblichiamo quotidianamente, il modello esponente quadratico regolarmente offre estrapolazioni più accurate della sua controparte esponenziale. Ci sono due aspetti per l'elaborazione dei modelli di cui non abbiamo diffusamente parlato. Il primo è che, nel ricercare il miglior fit, i dati più recenti sono tenuti in considerazione maggiormente. Il peso dei dati aumenta linearmente dal più vecchio (che non conta nulla) al più recente. Questo effetto è bene visibile nei grafici: i primissimi punti sono solitamente molto distanti dalle curve del modello. Il secondo aspetto riguarda il fatto che il modello viene aggiornato ogni giorno. Questa sua evoluzione permette di essere più accurato per la previsione al giorno successivo. Diventa però interessante come tali modelli evolvano nel tempo.

Il modello esponenziale quadratico ha due parametri significativi. Il primo riguarda il ritmo di diffusione *iniziale*. Abbiamo chiamato $K$ questo valore. Il secondo, $M$, indica quanto tale ritmo rallenta o accelera ogni giorno. Il caso in cui $M$ risulta vicino a zero corrisponde ad una crescita esponenziale pura. In tutti i modelli, $M$ risulta negativo, segno di un rallentamento.

Anche il modo in cui abbiamo ipotizzato il rallentamento è tutt'altro che sicuro. In realtà, onestamente pensiamo che non ci possa essere un modo "corretto" di modellizzare la diffusione quando nel fenomento entrano così tanti fattori sociali, psicologici, culturali e umani. La reazione dei popoli e la loro disciplina può fare un enorme differenza (e in un certo senso probabilmente già la sta facendo, se si confrontano gli andamenti tra Italia e Cina ad esempio). Possiamo quindi ipotizzare (e sperare) decise inversioni di tendenza nei prossimi giorni o settimane. 

Come variano $K$ e $M$ nel tempo? Mostriamo la tabella per il caso dei deceduti. 

 
```{r,echo=FALSE, results="show"}
knitr::kable(coeffts[[2]][-2], caption = 'Andamento temporale dei coefficienti di fit')
```

Come si evince, i parametri risultano *anticorrelati*: all'aumentare del primo, il secondo diminuisce e viceversa. Inoltre, il parametro $M$ nei primi giorni aveva un valore molto vicino a zero, segno di una crescita esponenziale. Tale valore è aumentato (in valore assoluto) con il passare dei giorni, fino ad assestarsi negli ultimi. Ne evinciamo che registriamo un rallentamento, che tale rallentamento prosegue, ma la *stabilità* di questi valori non ci permette di individuare una chiara inversione di tendenza. Se continuiamo ad estrapolare i risultati del modello, ci dobbiamo aspettare un numero di morti dell'ordine di 600 ancora per qualche giorno, fino a quando, all'incirca dal 27 marzo, il numero di deceduti giornalieri comincia a diminuire. 

Tuttavia, qui entra un punto già aperto, ma che non possiamo più ignorare: l'andamento asintotico del modello. Se continuiamo imperterriti ad estrapolare dal modello, otterremmo un numero *decrescente* di deceduti complessivi, mentre tale numero non può che aumentare, evidentemente. In sostanza, è molto probabile che, se le condizioni rimangono invariate. il modello in questione sia troppo ottimista nel prevedere il picco.

D'altro lato però l'effetto delle misure più restrittive potrebbe non essere totalmente preso in considerazione. Forse quello di oggi rimarrà davvero il giorno peggiore di questa epidemia. Purtroppo però, non c'è da scommetterci.





